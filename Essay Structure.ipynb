{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quantum-inspired genetic algorithm comparision with genetic algorithm for k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this paper we want to compare two diffrent algorithms for k-means clustering, first is Quantum Inspired Genetic Algorithm that we will implement it from Quantom Inspired genetic article, and second is a simple genetic algorithm from another article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> Introduction </li>\n",
    "    <li> Quantum-inspired genetic algorithm for k-means clustering implementation </li>\n",
    "    <li> Genetic algorithm for k-means clustering implementation </li>\n",
    "    <li> Comparison of two algorithm </li>\n",
    "    <li> Conclusion </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering plays an important role in many unsupervised learning\n",
    "areas, such as pattern recognition, data mining and knowledge\n",
    "discovery. Clustering problem can be summarized as: Given n\n",
    "points in Rd space and an integer k, find a set of k points, called centroids,\n",
    "such that the sum of the distances of each of the n points to\n",
    "its nearest centroid is minimized. Generally speaking, conventional\n",
    "clustering algorithms can be grouped into two main categories,\n",
    "namely hierarchical clustering algorithms and partitional clustering\n",
    "algorithms. A hierarchical clustering algorithm outputs a dendrogram,\n",
    "which is a tree structure showing a sequence of\n",
    "clusterings with each clustering being a partition of the dataset. Unlike the hierarchical clustering algorithm,\n",
    "the partitional clustering algorithms partition the data set\n",
    "into a number of clusters, and the output is only a single partition\n",
    "of the data set. The majority of partitional clustering algorithms\n",
    "obtain the partition through the maximization or minimization\n",
    "of some criterion functions. Recent researches show that the partitional\n",
    "clustering algorithms are well suited for clustering a large\n",
    "dataset due to their relatively low computational requirements. And the time complexity of\n",
    "the partitional algorithms is almost **linear**, which makes them\n",
    "widely used.\n",
    "Among the partitional clustering algorithms, the most famous\n",
    "one is **k-means clustering**. K-means clustering\n",
    "algorithm first randomly generates k initial cluster centroids. After\n",
    "several iterations of the algorithm, data can be classified into certain\n",
    "clusters by the criterion function, which makes the data close\n",
    "to each other in the same cluster and widely separated among clusters.\n",
    "However, the traditional k-means clustering algorithm has\n",
    "two drawbacks. The one is that the number of clusters has to be\n",
    "known in advance, and the other is that the clustering result is sensitive\n",
    "to the selection of initial cluster centroids and this may lead\n",
    "the algorithm converge to the local optima. Different datasets have\n",
    "different number of clusters, which is difficult to known beforehand,\n",
    "and the initial cluster centroids are selected randomly, which\n",
    "will make the algorithm converge to the different local optima.\n",
    "Therefore, a lot of research efforts have been conducted on mitigating\n",
    "the two drawbacks of the conventional k-means clustering\n",
    "algorithm. The **genetic algorithm** (GA) is one of the methods to\n",
    "avoid local optima and discover good initial centroids that lead\n",
    "to superior partitions under k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this paper we implemented two diffrent genetic algorithm for k-means algorithm :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quantum-inspired genetic algorithm for k-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The Overal Flowchart of KMQJA](./img/flowchart.PNG \"Representation of the Individual\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm for k-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means clustering method selects randomly k patterns from the dataset D which is of size n, as initial cluster centers.  \n",
    "These initial centers are also called seed-points. Let M(0) = {M(0) 1 ,M(0)2 , . . . ,M(0)k } be the set of initial\n",
    "seed points.  \n",
    "Remaining (n-k) patterns are assigned to their nearest cluster centers.  \n",
    "New centroid (mean) of each cluster is computed. Each pattern X Ñ” D is again assigned to the nearest hub and new centers are again found.\n",
    "This process is iterated until all centers (means) remain unchanged in two successive iterations.  \n",
    "The time multifaceted nature of the k-means technique is O (nkt), where n is the quantity of examples in the dataset, k is the quantity of groups and t is the quantity of emphases till the convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:**  \n",
    "k: the digit of clusters,  \n",
    "A: data set of n size.  \n",
    "**Output:**  \n",
    " An arrangement of k clusters.  \n",
    "**Routine:**\n",
    "1. Selection of k items from A (initial cluster centroid)\n",
    "2. Repeat until no changeK-Means Clustering & Application of Genetic Algorithm in K-Means Clustering  \n",
    " 2.1 Each item is allocated to the closest cluster to its nearest. (Distance of each item is calculated from selected cluster centroid using sum of squared error)  \n",
    " 2.2 Recalculate new cluster centroids\n",
    "3. Display the final generated clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum-inspired genetic algorithm for k-means clustering implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "    \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "    slow internet connections. Reports every 5% change in download progress.\"\"\"\n",
    "    global last_percent_reported\n",
    "    percent = int(count * blockSize * 100 / totalSize)\n",
    "    \n",
    "    if last_percent_reported != percent:\n",
    "        if percent % 5 == 0:\n",
    "            sys.stdout.write(\"%s%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "        last_percent_reported = percent\n",
    "        \n",
    "def read_df(filename, expected_bytes=None, force=False):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    dest_filename = os.path.join(data_root, filename)\n",
    "    dir = dest_filename[:dest_filename.rfind('/')]\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print('Attempting to download:', filename) \n",
    "        filename, _ = urlretrieve(root_url + filename, dest_filename, reporthook=download_progress_hook)\n",
    "        print('\\nDownload Complete!')        \n",
    "    return np.array(pd.read_csv(filename, header=None))\n",
    "\n",
    "# read_df(spectf_test)\n",
    "iris_addr = 'iris/iris.data'\n",
    "# wine_addr = 'wine/wine.data'\n",
    "# glass_addr = 'glass/glass.data'\n",
    "# spectf_train = 'spect/SPECTF.train'\n",
    "# spectf_test = 'spect/SPECTF.train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sda(num,clusterMembersNum=100) :\n",
    "    \"This function will generate random datasets : sda1,sda2,sda3\"\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    dataset = None\n",
    "    if num == 1 :\n",
    "        \"generating sda1 according to its table in essay\"\n",
    "        dataset = np.concatenate([np.random.uniform(0,20,(clusterMembersNum,2)),\n",
    "        np.random.uniform(40,60,(clusterMembersNum,2)),\n",
    "        np.random.uniform(80,100,(clusterMembersNum,2))])\n",
    "    elif num == 2 :\n",
    "        \"generating sda2 according to its table in essay\"\n",
    "        dataset = np.concatenate([np.random.uniform(0,20,(clusterMembersNum,2)),\n",
    "        np.random.uniform(40,60,(clusterMembersNum,2)),\n",
    "        np.random.uniform(80,100,(clusterMembersNum,2)),\n",
    "        np.array([[np.random.uniform(0,20),np.random.uniform(80,100)] for i in range(clusterMembersNum)])])\n",
    "    else :\n",
    "        \"generating sda3 according to its table in essay\"\n",
    "        dataset = np.concatenate([np.random.uniform(0,20,(clusterMembersNum,2)),\n",
    "        np.random.uniform(40,60,(clusterMembersNum,2)),\n",
    "        np.random.uniform(80,100,(clusterMembersNum,2)),\n",
    "        np.array([[np.random.uniform(80,100),np.random.uniform(0,20)] for i in range(clusterMembersNum)]),\n",
    "        np.array([[np.random.uniform(0,20),np.random.uniform(180,200)] for i in range(clusterMembersNum)]),\n",
    "        np.array([[np.random.uniform(180,200),np.random.uniform(0,20)] for i in range(clusterMembersNum)]),\n",
    "        np.array([[np.random.uniform(180,200),np.random.uniform(80,100)] for i in range(clusterMembersNum)]),\n",
    "        np.array([[np.random.uniform(180,200),np.random.uniform(180,200)] for i in range(clusterMembersNum)])])\n",
    "    return np.array(dataset)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(data):\n",
    "    normData = data\n",
    "    data = data.astype(float)\n",
    "    normData = normData.astype(float)\n",
    "    for i in range(0, data.shape[1]):\n",
    "        tmp = data.iloc[:, i]\n",
    "        # max of each column\n",
    "        maxElement = np.amax(tmp)\n",
    "        # min of each column\n",
    "        minElement = np.amin(tmp)\n",
    "\n",
    "        # norm_dat.shape[0] : size of row\n",
    "        for j in range(0, normData.shape[0]):\n",
    "            normData[i][j] = float(\n",
    "                data[i][j] - minElement) / (maxElement - minElement)\n",
    "\n",
    "    normData.to_csv('result/norm_data.csv', index=None, header=None)\n",
    "    return normData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6f75e5763b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mminmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-e5d26a4c54c9>\u001b[0m in \u001b[0;36mread_df\u001b[0;34m(filename, expected_bytes, force)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_bytes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m\"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdest_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdest_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdest_filename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_root' is not defined"
     ]
    }
   ],
   "source": [
    "minmax(pd.DataFrame(read_df(iris_addr)[:,:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall flowchart of KMQGA :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import libraries, we will needed in future :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "# from six.moves import cPickle as pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "               [4, 2], [4, 4], [4, 0]])\n",
    "kmeans = KMeans(n_clusters=6, random_state=0).fit(X)\n",
    "kmeans.cluster_centers_\n",
    "# kmeans.predict([[0, 0], [4, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalizing constants, we are needed in future :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data loading params\n",
    "data_root = ''\n",
    "root_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "iris_addr = 'iris/iris.data'\n",
    "wine_addr = 'wine/wine.data'\n",
    "glass_addr = 'glass/glass.data'\n",
    "spectf_train = 'spect/SPECTF.train'\n",
    "spectf_test = 'spect/SPECTF.test'\n",
    "last_percent_reported = None # needed for showing progress in download\n",
    "\n",
    "# seed initialization\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# color map for data visualization\n",
    "LABEL_COLOR_MAP = {\n",
    "    0 : 'r',\n",
    "    1 : '#006266',\n",
    "    2 : 'g',\n",
    "    3 : 'B',\n",
    "    4 : 'c' ,\n",
    "    5 : 'm' ,\n",
    "    6 : 'y' ,\n",
    "    7 : '#C4E538' \n",
    "}\n",
    "\n",
    "# Quantum genetic algorithm essay params\n",
    "pop_size = 100\n",
    "N_max = (100,300)\n",
    "n_max = 15\n",
    "m_max = 25\n",
    "pc = 0.9\n",
    "pm = 0.01\n",
    "pcc = (1 - pc) * random.random() + pc\n",
    "pmm = (2*pm - pm) * random.random() + pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class will provide us with function, we will be needed in future :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ToolBox :\n",
    "    @staticmethod\n",
    "    def translate(value, leftMin, leftMax, rightMin, rightMax):\n",
    "        \"\"\"this function will map value from range(leftMin,leftMax)\n",
    "        to range(rightMin,rightMax)\"\"\"\n",
    "        # Figure out how 'wide' each range is\n",
    "        leftSpan = leftMax - leftMin\n",
    "        rightSpan = rightMax - rightMin\n",
    "\n",
    "        # Convert the left range into a 0-1 range (float)\n",
    "        valueScaled = float(value - leftMin) / float(leftSpan)\n",
    "        value = int(rightMin + (valueScaled * rightSpan))\n",
    "        if value == rightMax :\n",
    "            value = rightMax - 1\n",
    "        # Convert the 0-1 range into a value in the right range.\n",
    "        return value\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclideanDistance(x,y):\n",
    "        \"return euclidean distance between x and y\"\n",
    "        e = 0\n",
    "        for i,j in zip(x,y):\n",
    "            e += (i - j)**2\n",
    "        return np.sqrt(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qbit Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Qbit :\n",
    "    def __init__(self) :\n",
    "        self.a = random.random()\n",
    "        self.b = np.sqrt(1 - self.a**2)\n",
    "        self.bit = None\n",
    "    \n",
    "    def __str__(self) :\n",
    "        return '({}, {})'.format(self.a,self.b)\n",
    "\n",
    "    def mutate(self) :\n",
    "        self.a,self.b = self.b,self.a\n",
    "        \n",
    "    def toBit(self) :\n",
    "        \"transform qbit to zero or one\"\n",
    "        if random.random() < self.a**2 :\n",
    "            self.bit = 0\n",
    "        else :\n",
    "            self.bit = 1\n",
    "        return self.bit     \n",
    "            \n",
    "    def rotate(self,bi,isGreater) :\n",
    "        dt = 0\n",
    "        sign = 0\n",
    "        ri = self.bit\n",
    "        positive = self.a * self.b > 0\n",
    "        aZero = not self.a\n",
    "        bZero = not self.b\n",
    "        # initializing angle and sign of rotation \n",
    "        if(isGreater) :\n",
    "            if not ri and bi :\n",
    "                dt = np.pi * .05\n",
    "                if aZero :\n",
    "                    sign = 1\n",
    "                elif bZero :\n",
    "                    sign = 0\n",
    "                elif positive :\n",
    "                    sign = -1\n",
    "                else :\n",
    "                    sign = 1\n",
    "            elif ri and not bi :\n",
    "                dt = np.pi * .025\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "            elif ri and bi :\n",
    "                dt = np.pi * .025\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "        else :\n",
    "            if ri and not bi :\n",
    "                dt = np.pi * .01\n",
    "                if aZero :\n",
    "                    sign = 1\n",
    "                elif bZero :\n",
    "                    sign = 0\n",
    "                elif positive :\n",
    "                    sign = -1\n",
    "                else :\n",
    "                    sign = 1\n",
    "            elif ri and bi :\n",
    "                dt = np.pi * .005\n",
    "                if aZero :\n",
    "                    sign = 0\n",
    "                elif bZero :\n",
    "                    sign = 1\n",
    "                elif positive :\n",
    "                    sign = 1\n",
    "                else :\n",
    "                    sign = -1\n",
    "        \n",
    "        t = sign * dt\n",
    "        self.a,self.b = np.dot(\n",
    "            np.array([[np.cos(t),-np.sin(t)],[np.sin(t),np.cos(t)]]),np.array([self.a,self.b])\n",
    "        )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Pattern :\n",
    "    def __init__(self,size) :\n",
    "        self.size = size       \n",
    "        self.clusterMembers = None\n",
    "        self.centroid = None\n",
    "        self.id = np.array([])\n",
    "        for _ in range(size) :\n",
    "            self.id = np.append(self.id,Qbit())\n",
    "        self.real = None\n",
    "           \n",
    "    def __str__(self) :\n",
    "        return '({})'.format(self.real)\n",
    "    \n",
    "    def toReal(self,maxValue) :\n",
    "        \"transform pattern to real number which is centroid position\"\n",
    "        self.real = 0\n",
    "        for i,qbit in enumerate(self.id) :\n",
    "            self.real += qbit.toBit()*np.power(2,self.size - i - 1)\n",
    "        self.real = ToolBox.translate(\n",
    "                self.real,0,\n",
    "                np.power(2,len(self.id))-1,\n",
    "                0,maxValue) # fit generated number to length of the dataset\n",
    "        return self.real\n",
    "    \n",
    "    def rotate(self,b,isGreater) :\n",
    "        \"rotate each qbit\"\n",
    "        for i,qbit in enumerate(self.id) :\n",
    "            qbit.rotate(b.id[i],isGreater)\n",
    "            \n",
    "    def mutate(self,pos) :\n",
    "        \"will mutate the qbit in position {pos} in pattern\"\n",
    "        self.id[pos].mutate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chromosome Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Chromosome :\n",
    "    def __init__(self,cSize,iSize) :\n",
    "        self.size = cSize\n",
    "        self.iSize = iSize\n",
    "        self.fitness = float('-inf')\n",
    "        self.r = np.array([])\n",
    "        if (cSize == 0) :\n",
    "            print(cSize)\n",
    "            print('hi babe')\n",
    "        for _ in range(cSize) :\n",
    "            self.r = np.append(self.r,Pattern(iSize))\n",
    "    \n",
    "    def __str__(self) :\n",
    "        return str([p.real for p in self.r])\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return self.iSize * self.size\n",
    "    \n",
    "    def toReal(self,dpSize,dataset) :\n",
    "        \"transforming each pattern to real number\"\n",
    "        for p in self.r :\n",
    "            p.toReal(dpSize)\n",
    "        isEqualReal = True\n",
    "        while isEqualReal :\n",
    "            isEqualReal = False\n",
    "            #check if there is two pattern with same real number\n",
    "            for p in self.r :\n",
    "                for p2 in self.r :\n",
    "                    if p != p2 :\n",
    "                        while np.min([i == j for i,j in zip(dataset[p.real],dataset[p2.real])]) :\n",
    "                            isEqualReal = True\n",
    "                            p.toReal(dpSize)\n",
    "\n",
    "    def rotate(self,b,isGreater) :\n",
    "        for i,pattern in enumerate(self.r) :\n",
    "            pattern.rotate(b.r[i],isGreater)\n",
    "            \n",
    "    def mutate(self) :\n",
    "        \"generating a random number and change a and b in position of rnd in chromosome\"\n",
    "        rnd = np.random.randint(0,self.__len__())\n",
    "        pos = self.patternPos(rnd)\n",
    "        self.r[pos[0]].mutate(pos[1])\n",
    "        \n",
    "    def computeFitness(self,dataset) :\n",
    "        self.toReal(len(dataset),dataset)\n",
    "#         self._kMeansClustering(dataset)\n",
    "        self._alocateCluster(dataset)\n",
    "        self._calculateCentroid(dataset)\n",
    "        s = [np.mean([ToolBox.euclideanDistance(pattern.centroid, member) \\\n",
    "                      for member in dataset[pattern.clusterMembers]]) for pattern in self.r]\n",
    "        self.fitness = 1/np.mean([np.max([(s[i] + s[j])/ToolBox.euclideanDistance(pattern.centroid,pattern2.centroid) \\\n",
    "                                for j,pattern2 in enumerate(self.r) if i != j]) for i,pattern in enumerate(self.r)])\n",
    "        return self.fitness\n",
    "       \n",
    "    def _kMeansClustering(self,dataset) :\n",
    "                    \n",
    "        kmeans = KMeans(n_clusters=self.size,init=np.array([dataset[pattern.real] for pattern in self.r]),n_init=1).fit(dataset)\n",
    "#         kmeans = KMeans(n_clusters=self.size).fit(dataset)\n",
    "\n",
    "        \"Alocating data points to each cluster via their euclidean distance\"\n",
    "        for i,pattern in enumerate(self.r) :\n",
    "            self.r[i].clusterMembers = np.array([]).astype(int)\n",
    "        \n",
    "        for i,label in enumerate(kmeans.labels_) :\n",
    "            self.r[label].clusterMembers = np.append(self.r[label].clusterMembers,i)\n",
    "        \n",
    "        \"Calculate each centroid point via mean of every cluster member\"      \n",
    "        self._calculateCentroid(dataset)\n",
    "#         for i,pattern in enumerate(self.r):\n",
    "#             # calculating centroid for every cluster\n",
    "#             self.r[i].centroid = kmeans.cluster_centers_[i]\n",
    "                    \n",
    "    def _alocateCluster(self,dataset) :\n",
    "        \"Alocating data points to each cluster via their euclidean distance\"\n",
    "        for i,centroid in enumerate(self.r) :\n",
    "            self.r[i].clusterMembers = np.array([]).astype(int)\n",
    "        \n",
    "        for i,data in enumerate(dataset):\n",
    "            minDist = float('inf')\n",
    "            minCentroidIndex = -1\n",
    "            for j,centroid in enumerate(self.r) :\n",
    "                dist = ToolBox.euclideanDistance(dataset[i],dataset[centroid.real]) \n",
    "                if dist < minDist :\n",
    "                    minCentroidIndex = j\n",
    "                    minDist = dist\n",
    "            self.r[minCentroidIndex].clusterMembers = np.append(self.r[minCentroidIndex].clusterMembers,i)\n",
    "            \n",
    "    def _calculateCentroid(self,dataset) :\n",
    "        \"Calculate each centroid point via mean of every cluster member\"\n",
    "        for pattern in self.r:\n",
    "            # calculating centroid for every cluster\n",
    "            if len(pattern.clusterMembers) == 0 :       \n",
    "                print(pattern.clusterMembers)\n",
    "            pattern.centroid = np.mean(dataset[pattern.clusterMembers],axis=0)\n",
    "                           \n",
    "    def patternPos(self,qbitPos) :\n",
    "        \"\"\"calculating the position of the qbit in pattern\n",
    "        return (patternPos,qbitInPatternPos)\"\"\"\n",
    "\n",
    "        if qbitPos >= self.__len__() :\n",
    "            print('warning ' + str(qbitPos))\n",
    "            print(int(np.floor(qbitPos/self.iSize)),int(qbitPos % self.iSize))\n",
    "            \n",
    "        return (int(np.floor(qbitPos/self.iSize)),int(qbitPos % self.iSize))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Population :\n",
    "    def __init__(self,pSize,cSize,iSize) :\n",
    "        self.size = pSize\n",
    "        self.cSize = cSize\n",
    "        self.iSize = iSize\n",
    "        self.bestChromosomeIndex = None\n",
    "        self.p = np.array([])\n",
    "        for _ in range(pSize) :\n",
    "            self.p = np.append(self.p,Chromosome(cSize,iSize))\n",
    "\n",
    "    def toReal(self) :\n",
    "        for c in self.p :\n",
    "            c.toReal()\n",
    "\n",
    "    def rotate(self,bestChoromosome) :\n",
    "        \n",
    "        for chromosome in self.p :\n",
    "            # checking if the length of the chromosomes are the same as th\n",
    "            if len(chromosome) > len(bestChoromosome) :\n",
    "                chrom = Chromosome(int(np.ceil(len(bestChoromosome)/self.iSize)),self.iSize)\n",
    "                for i in range(len(chrom)) :\n",
    "                    chromPatternPos = chrom.patternPos(i)\n",
    "                    chrom.r[chromPatternPos[0]].id[chromPatternPos[1]] = chromosome.r[chromPatternPos[0]].id[chromPatternPos[1]]  \n",
    "                chromosome = chrom\n",
    "            elif len(chromosome) < len(bestChoromosome) :\n",
    "                chrom = Chromosome(int(np.ceil(len(bestChoromosome)/self.iSize)),self.iSize)\n",
    "                for i in range(len(chromosome)) :\n",
    "                    chromPatternPos = chrom.patternPos(i)\n",
    "                    chrom.r[chromPatternPos[0]].id[chromPatternPos[1]] = chromosome.r[chromPatternPos[0]].id[chromPatternPos[1]]  \n",
    "                chromosome = chrom\n",
    "            chromosome.rotate(bestChoromosome,bestChoromosome.fitness > chromosome.fitness)\n",
    "        \n",
    "    def mutate(self,prob) :\n",
    "        for chromosome in self.p :\n",
    "            rnd = random.random()\n",
    "            if rnd < prob :\n",
    "                chromosome.mutate()\n",
    "\n",
    "    def computeFitness(self,dataset) :\n",
    "        maxFit = float('-inf')\n",
    "        for i,chromosome in enumerate(self.p) :\n",
    "            chromosome.computeFitness(dataset)\n",
    "            if chromosome.fitness > maxFit :\n",
    "                maxFit = chromosome.fitness\n",
    "                self.bestChromosomeIndex = i\n",
    "        return maxFit\n",
    "\n",
    "    def eliteSelection(self,population) :\n",
    "        maxFit = np.max([ch.fitness for ch in population.p])\n",
    "        if self.p[self.bestChromosomeIndex].fitness > maxFit :\n",
    "            for ch in sorted(self.p, key=lambda x: x.fitness) :\n",
    "                if ch.fitness > maxFit :\n",
    "                    population.p[np.random.randint(0,self.size)] = copy.deepcopy(ch)\n",
    "        return population\n",
    "\n",
    "    def selection(self) :    \n",
    "        population = Population(self.size,self.cSize,self.iSize)\n",
    "        # Roulette selection\n",
    "        for i in range(self.size) :\n",
    "            population.p[i] = copy.deepcopy(self.roulette())\n",
    "        # Elite selection\n",
    "        maxFit = np.max([ch.fitness for ch in population.p])\n",
    "        if self.p[self.bestChromosomeIndex].fitness > maxFit :\n",
    "            for ch in sorted(self.p, key=lambda x: x.fitness) :\n",
    "                if ch.fitness > maxFit :\n",
    "                    population.p[np.random.randint(0,self.size)] = copy.deepcopy(ch)\n",
    "        return population \n",
    "    \n",
    "    def roulette(self) :\n",
    "        sumFit = np.sum([ch.fitness for ch in self.p])\n",
    "        pick = random.uniform(0, sumFit)\n",
    "        current = 0\n",
    "        for chromosome in self.p:\n",
    "            current += chromosome.fitness\n",
    "            if current > pick:\n",
    "                return chromosome\n",
    "\n",
    "    def catastrophe(self,bestChromosome) :\n",
    "        self.__init__(self.size,self.cSize,self.iSize)\n",
    "        self.p[0] = copy.deepcopy(bestChromosome)\n",
    "        \n",
    "    def crossover(self,prob,method='first',dataset=None) :\n",
    "        population = Population(self.size,self.cSize,self.iSize)\n",
    "        for i in range(int(self.size/2)) :\n",
    "            self._mating(prob,population,i,method)\n",
    "        if method == 'first' :\n",
    "            population.computeFitness(dataset)\n",
    "            return self.eliteSelection(population)\n",
    "        else :\n",
    "            return population\n",
    "    \n",
    "    def _mating(self,prob,population,j,method='first') :\n",
    "        firstPoint = 0\n",
    "        secondPoint = 0\n",
    "        isDiffrentParent = False\n",
    "        if method == 'first' :\n",
    "            parent1 = copy.deepcopy(self.roulette())\n",
    "            parent2 = copy.deepcopy(self.roulette())\n",
    "        else :\n",
    "            parent1 = copy.deepcopy(self.p[np.random.randint(0,self.size)])\n",
    "            parent2 = copy.deepcopy(self.p[np.random.randint(0,self.size)])\n",
    "        # finding the standard points for crossover\n",
    "        if random.random() <= prob:\n",
    "            isStandardPoint = False\n",
    "            while (not isStandardPoint) :\n",
    "                firstPoint = np.random.randint(0,len(parent1))\n",
    "                secondPoint = np.random.randint(0,len(parent2))\n",
    "                firstChildLen = (firstPoint + len(parent2) - secondPoint)\n",
    "                secondChildLen = (len(parent1) - firstPoint + secondPoint)\n",
    "                isStandardPoint = (firstChildLen % self.iSize == 0) and (firstChildLen/self.iSize > 1) and \\\n",
    "                    (secondChildLen % self.iSize == 0) and (secondChildLen/self.iSize > 1)\n",
    "        # 2 point crossover\n",
    "        firstChildLen = firstPoint + len(parent2) - secondPoint\n",
    "        secondChildLen = len(parent1) - firstPoint + secondPoint\n",
    "        child1 = Chromosome(int(np.ceil(firstChildLen/self.iSize)),self.iSize)\n",
    "        child2 = Chromosome(int(np.ceil(secondChildLen/self.iSize)),self.iSize)\n",
    "        for i in range(firstChildLen) :\n",
    "            childPatternPos = child1.patternPos(i)\n",
    "            if i < firstPoint :\n",
    "                parentPatternPos = parent1.patternPos(i)\n",
    "                child1.r[childPatternPos[0]].id[childPatternPos[1]] = parent1.r[parentPatternPos[0]].id[parentPatternPos[1]]\n",
    "            else :\n",
    "                parentPatternPos = parent2.patternPos(secondPoint + (i - firstPoint))\n",
    "                child1.r[childPatternPos[0]].id[childPatternPos[1]] = parent2.r[parentPatternPos[0]].id[parentPatternPos[1]]\n",
    "\n",
    "        for i in range(secondChildLen) :\n",
    "            childPatternPos = child2.patternPos(i)\n",
    "            if i < secondPoint :\n",
    "                parentPatternPos = parent2.patternPos(i)\n",
    "                child2.r[childPatternPos[0]].id[childPatternPos[1]] = parent2.r[parentPatternPos[0]].id[parentPatternPos[1]]\n",
    "            else :\n",
    "                parentPatternPos = parent1.patternPos(firstPoint + (i - secondPoint))\n",
    "                child2.r[childPatternPos[0]].id[childPatternPos[1]] = parent1.r[parentPatternPos[0]].id[parentPatternPos[1]]\n",
    "        population.p[2*j] = copy.deepcopy(child2)                \n",
    "        population.p[2*j+1] = copy.deepcopy(child1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def quantumGeneticAlgorithm(dataset,popSize,pcc,pc,pm,pmm,preCriterion,catCriterion,iterNum,initPatternNum = None) :\n",
    "    \"main method, we will implement algorithm in it\"\n",
    "    bestFitArr = np.array([])\n",
    "    bestFitCentArr = np.array([])\n",
    "    bestChromosome = None\n",
    "    bestSameIter = 0\n",
    "    bestFitness = float('-inf')\n",
    "    populations = np.full((iterNum),None)\n",
    "    # randomly choosing initial pattern number in a chromosome in range(2,np.sqrt(N) + 1)\n",
    "    if initPatternNum :\n",
    "        initialPatternNum = initPatternNum\n",
    "    else :\n",
    "        initialPatternNum = random.randint(2,np.floor(np.sqrt(len(dataset)) + 1))\n",
    "    PatternSize = int(np.ceil(np.log2(len(dataset))))\n",
    "    populations[0] = Population(popSize,initialPatternNum,PatternSize)\n",
    "    bestFit = populations[0].computeFitness(dataset)\n",
    "    bestFitArr = np.append(bestFitArr,bestFit)\n",
    "    bestFitCentArr = np.append(bestFitCentArr,len(populations[0].p[populations[0].bestChromosomeIndex].r))\n",
    "    if bestFit > bestFitness :\n",
    "        bestChromosome = copy.deepcopy(populations[0].p[populations[0].bestChromosomeIndex])\n",
    "        bestFitness = bestFit\n",
    "        bestSameIter = 0\n",
    "    else :\n",
    "        bestSameIter += 1\n",
    "    for generation in range(1,iterNum) :   \n",
    "        print('--------------------generation : {} ------------------'.format(generation))\n",
    "        print('best fitness : {}'.format(bestFit))\n",
    "        print('best chromosome cluster numbers : {}'.format(len(bestChromosome.r)))\n",
    "        print('best chrom fit : {}'.format(bestFitness))\n",
    "        print('best chrom cluster numbers : {}'.format(len(bestChromosome.r)))\n",
    "        if bestSameIter < preCriterion :\n",
    "            populations[generation - 1] = populations[generation - 1].selection()\n",
    "#             populations[generation - 1] = populations[generation - 1].crossover(pc,'second',dataset)\n",
    "            populations[generation - 1].mutate(pm)\n",
    "            bestFit = populations[generation - 1].computeFitness(dataset)\n",
    "            if bestFit > bestFitness :\n",
    "                bestChromosome = copy.deepcopy(populations[generation - 1].p[populations[generation - 1].bestChromosomeIndex])\n",
    "                bestFitness = bestFit\n",
    "                bestSameIter = 0\n",
    "            if bestSameIter < catCriterion :\n",
    "                populations[generation - 1].rotate(bestChromosome)\n",
    "            else :\n",
    "                populations[generation - 1].catastrophe(bestChromosome)\n",
    "                bestSameIter = 0\n",
    "        else :\n",
    "            populations[generation - 1] = populations[generation - 1].selection()\n",
    "#             populations[generation - 1] = populations[generation - 1].crossover(pcc,'second',dataset)\n",
    "            populations[generation - 1].mutate(pmm)\n",
    "            bestFit = populations[generation - 1].computeFitness(dataset)\n",
    "            if bestFit > bestFitness :\n",
    "                bestChromosome = copy.deepcopy(populations[generation - 1].p[populations[generation - 1].bestChromosomeIndex])\n",
    "                bestFitness = bestFit\n",
    "                bestSameIter = 0\n",
    "            if bestSameIter < catCriterion :\n",
    "                populations[generation - 1].rotate(bestChromosome)\n",
    "            else :\n",
    "                populations[generation - 1].catastrophe(bestChromosome)\n",
    "                bestSameIter = 0\n",
    "        \n",
    "        populations[generation] = populations[generation - 1]\n",
    "        bestFit = populations[generation].computeFitness(dataset)\n",
    "        bestFitCentArr = np.append(bestFitCentArr,len(populations[generation].p[populations[generation].bestChromosomeIndex].r))\n",
    "        bestFitArr = np.append(bestFitArr,bestFit)\n",
    "        if bestFit > bestFitness :\n",
    "            bestChromosome = copy.deepcopy(populations[generation].p[populations[generation].bestChromosomeIndex])\n",
    "            bestFitness = bestFit\n",
    "            bestSameIter = 0\n",
    "        else :\n",
    "            bestSameIter += 1\n",
    "    return bestFitArr,bestChromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rotation Table](./img/RotationTable.PNG \"Reotation Table\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def colorMapGenerator(clusters,dataset) :\n",
    "    \"this color will assign color to each data point in dataset\"\n",
    "    c = np.full((len(dataset)),None)\n",
    "    for i,cluster in enumerate(clusters) :\n",
    "        c[cluster.clusterMembers] = LABEL_COLOR_MAP[i]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KMQGA on first simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sda1 = sda(1)\n",
    "sda1_response = quantumGeneticAlgorithm(sda1,pop_size,pcc,pc,pm,pmm,n_max,m_max,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(10)),sda1_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(sda1[:, 0], sda1[:, 1],c=colorMapGenerator(sda1_response[1].r,sda1), s=50, cmap='viridis')\n",
    "plt.scatter(sda1[:, 0], sda1[:, 1], s=50, cmap='viridis')\n",
    "centers = np.array([pattern.centroid for pattern in sda1_response[1].r])\n",
    "plt.scatter(centers[:,0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as u see it found all of the clusters correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KMQGA on second simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sda2 = sda(2)\n",
    "sda2_response = quantumGeneticAlgorithm(sda2,pop_size,pcc,pc,pm,pmm,n_max,m_max,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(10)),sda2_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as u see KMQGA is so non-deterministic and it can't converge to anything slowly , its fitness value quickly changed in every generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(sda2[:, 0], sda2[:, 1],c=colorMapGenerator(sda2_response[1].r,sda2), s=50, cmap='viridis')\n",
    "centers = np.array([pattern.centroid for pattern in sda2_response[1].r])\n",
    "plt.scatter(centers[:,0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running KMQGA on Third simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sda3 = sda(3)\n",
    "sda3_response = quantumGeneticAlgorithm(sda3,pop_size,pcc,pc,pm,pmm,n_max,m_max,N_max[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(N_max[1])),sda3_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(sda3[:, 0], sda3[:, 1],c=colorMapGenerator(sda3_response[1].r,sda3), s=50, cmap='red')\n",
    "plt.scatter(sda3[:, 0], sda3[:, 1], s=50, cmap='red')\n",
    "centers = np.array([pattern.centroid for pattern in sda3_response[1].r])\n",
    "plt.scatter(centers[:,0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_dataset = read_df(iris_addr)[:,:-1].astype(float)\n",
    "iris_response = quantumGeneticAlgorithm(iris_dataset,pop_size,pcc,pc,pm,pmm,n_max,m_max,N_max[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(300)),iris_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wine_dataset = read_df(wine_addr)[:,1:]\n",
    "# wine_dataset.shape\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#                [4, 2], [4, 4], [4, 0]])\n",
    "# kmeans = KMeans(n_clusters=3,init=np.array([wine_dataset[1],wine_dataset[10],wine_dataset[80]]),n_init=1).fit(wine_dataset)\n",
    "# kmeans.cluster_centers_\n",
    "wine_response = quantumGeneticAlgorithm(wine_dataset,pop_size,pcc,pc,pm,pmm,n_max,m_max,N_max[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = read_df(wine_addr)[:,1:]\n",
    "wine_dataset.shape\n",
    "# X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "#                [4, 2], [4, 4], [4, 0]])\n",
    "kmeans = KMeans(n_clusters=3,init=np.array([wine_dataset[1],wine_dataset[10],wine_dataset[80]]),n_init=1).fit(wine_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "centers = np.array([pattern.centroid for pattern in wine_response[1].r])\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(N_max[1])),wine_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_dataset = read_df(glass_addr)\n",
    "glass_dataset\n",
    "glass_response = quantumGeneticAlgorithm(glass_dataset,pop_size,pcc,pc,pm,pmm,n_max,m_max,N_max[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "centers = np.array([pattern.centroid for pattern in glass_response[1].r])\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(N_max[1])),glass_response[0])\n",
    "plt.ylabel('fitness value')\n",
    "plt.xlabel('iteration number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectf_dataset = read_df(spectf_train)[:,1:]\n",
    "spectf_response = quantumGeneticAlgorithm(spectf_dataset,pop_size,pcc,pc,pm,pmm,n_max,m_max,N_max[1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_point_bruteforce(dataset) :\n",
    "    bestFit = float('-inf')\n",
    "    bestI = 0\n",
    "    bestJ = 1\n",
    "    bestZ = 2\n",
    "    for first in range(dataset.shape[0]) :\n",
    "        for second in range(first,dataset.shape[0]) :\n",
    "            if equality(dataset[first],dataset[second]) :\n",
    "                continue\n",
    "            for third in range(second,dataset.shape[0]) :\n",
    "\n",
    "                if equality(dataset[first],dataset[third]) :\n",
    "                    continue\n",
    "                if equality(dataset[second],dataset[third]) :\n",
    "                    continue\n",
    "                fitness = calFitThird(dataset,first,second,third)\n",
    "                if fitness > bestFit :\n",
    "                    bestFit = fitness\n",
    "                    bestI = first\n",
    "                    bestJ = second  \n",
    "                    bestZ = third\n",
    "                if((first + second + third) % 300 == 0) :\n",
    "                    print(bestFit)\n",
    "    print('------------------------------------')\n",
    "    print(bestFit)\n",
    "    return bestFit,bestI,bestJ,bestZ\n",
    "\n",
    "\n",
    "def calFitThird(dataset,first,second,third) :\n",
    "    clusterMembers = np.array([None,None,None])\n",
    "    for i,pattern in enumerate(clusterMembers) :\n",
    "        clusterMembers[i] = np.array([]).astype(int)\n",
    "    for i,data in enumerate(dataset):\n",
    "        minDist = float('inf')\n",
    "        minCentroidIndex = -1\n",
    "        for j,centroid in enumerate([first,second,third]) :\n",
    "            dist = ToolBox.euclideanDistance(dataset[i],dataset[centroid]) \n",
    "            if dist < minDist :\n",
    "                minCentroidIndex = j\n",
    "                minDist = dist\n",
    "        clusterMembers[minCentroidIndex] = np.append(clusterMembers[minCentroidIndex],i)\n",
    "    \"Calculate each centroid point via mean of every cluster member\"\n",
    "    centroids = np.array([None,None,None])\n",
    "    for i,cm in enumerate(clusterMembers):\n",
    "        # calculating centroid for every cluster\n",
    "        if len(cm) == 0 :       \n",
    "            print(cm)\n",
    "        centroids[i] = np.mean(dataset[cm],axis=0)\n",
    "    \n",
    "    s = [np.mean([ToolBox.euclideanDistance(pattern, member) \\\n",
    "      for member in dataset[clusterMembers[i]]]) for i,pattern in enumerate(centroids)]\n",
    "    fitness = 1/np.mean([np.max([(s[i] + s[j])/ToolBox.euclideanDistance(pattern,pattern2) \\\n",
    "                    for j,pattern2 in enumerate(centroids) if i != j]) for i,pattern in enumerate(centroids)])\n",
    "    return fitness\n",
    "\n",
    "def two_point_bruteforce(dataset) : \n",
    "    bestFit = float('-inf')\n",
    "    bestI = 0\n",
    "    bestJ = 1\n",
    "    for first in range(dataset.shape[0]) :\n",
    "        for second in range(first,dataset.shape[0]) :\n",
    "            if equality(dataset[first],dataset[second]) :\n",
    "                continue\n",
    "            fitness = calFit_2(dataset,first,second)\n",
    "            if fitness > bestFit :\n",
    "                bestFit = fitness\n",
    "                bestI = first\n",
    "                bestJ = second  \n",
    "            if((first + second) % 100 == 0) :\n",
    "                print(bestFit)\n",
    "    return bestFit,bestI,bestJ\n",
    "    \n",
    "def calFit(dataset,first,second) :\n",
    "    kmeans = KMeans(n_clusters=2,init=np.array([dataset[pattern] for pattern in [first,second]]),n_init=1).fit(dataset)\n",
    "    clusterMembers = np.array([None,None])\n",
    "    for i,pattern in enumerate(clusterMembers) :\n",
    "        clusterMembers[i] = np.array([]).astype(int)\n",
    "    for i,label in enumerate(kmeans.labels_) :\n",
    "        clusterMembers[label] = np.append(clusterMembers[label],i)\n",
    "    \n",
    "    \"Calculate each centroid point via mean of every cluster member\"\n",
    "    centroids = np.array([None,None])\n",
    "    for i,cm in enumerate(clusterMembers):\n",
    "        # calculating centroid for every cluster\n",
    "        if len(cm) == 0 :       \n",
    "            print(cm)\n",
    "        centroids[i] = np.mean(dataset[cm],axis=0)\n",
    "    \n",
    "    s = [np.mean([ToolBox.euclideanDistance(pattern, member) \\\n",
    "      for member in dataset[clusterMembers[i]]]) for i,pattern in enumerate(centroids)]\n",
    "    fitness = 1/np.mean([np.max([(s[i] + s[j])/ToolBox.euclideanDistance(pattern,pattern2) \\\n",
    "                    for j,pattern2 in enumerate(centroids) if i != j]) for i,pattern in enumerate(centroids)])\n",
    "    return fitness\n",
    "\n",
    "def calFit_2(dataset,first,second) :\n",
    "#     kmeans = KMeans(n_clusters=2,init=np.array([dataset[pattern] for pattern in [first,second]]),n_init=1).fit(dataset)\n",
    "    clusterMembers = np.array([None,None])\n",
    "    for i,pattern in enumerate(clusterMembers) :\n",
    "        clusterMembers[i] = np.array([]).astype(int)\n",
    "    for i,data in enumerate(dataset):\n",
    "        minDist = float('inf')\n",
    "        minCentroidIndex = -1\n",
    "        for j,centroid in enumerate([first,second]) :\n",
    "            dist = ToolBox.euclideanDistance(dataset[i],dataset[centroid]) \n",
    "            if dist < minDist :\n",
    "                minCentroidIndex = j\n",
    "                minDist = dist\n",
    "        clusterMembers[minCentroidIndex] = np.append(clusterMembers[minCentroidIndex],i)\n",
    "#     print(clusterMembers)\n",
    "    \"Calculate each centroid point via mean of every cluster member\"\n",
    "    centroids = np.array([None,None])\n",
    "    for i,cm in enumerate(clusterMembers):\n",
    "        # calculating centroid for every cluster\n",
    "        if len(cm) == 0 :       \n",
    "            print(cm)\n",
    "        centroids[i] = np.mean(dataset[cm],axis=0)\n",
    "    \n",
    "    s = [np.mean([ToolBox.euclideanDistance(pattern, member) \\\n",
    "      for member in dataset[clusterMembers[i]]]) for i,pattern in enumerate(centroids)]\n",
    "    fitness = 1/np.mean([np.max([(s[i] + s[j])/ToolBox.euclideanDistance(pattern,pattern2) \\\n",
    "                    for j,pattern2 in enumerate(centroids) if i != j]) for i,pattern in enumerate(centroids)])\n",
    "    return fitness\n",
    "\n",
    "def equality(firstDp,secondDp) :\n",
    "    if (len(firstDp) != len(secondDp)) :\n",
    "        print(\"Error Length of array \")\n",
    "        return None\n",
    "    for i in range(len(firstDp)) :\n",
    "        if firstDp[i] != secondDp[i] :\n",
    "            return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectf_dataset = read_df(spectf_train)[:,1:]\n",
    "# fitness,bestI,bestJ = two_point_bruteforce(spectf_dataset)\n",
    "spectf_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dataset = read_df(wine_addr)[:,1:]\n",
    "fitness,bestI,bestJ,bestZ = three_point_bruteforce(np.array(minmax(pd.DataFrame(wine_dataset))))\n",
    "wine_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = read_df(iris_addr)[:,:-1].astype(float)\n",
    "fitness,bestI,bestJ,bestZ = three_point_bruteforce(np.array(minmax(pd.DataFrame(read_df(iris_addr)[:,:-1]))))\n",
    "iris_dataset.shapeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_dataset = read_df(glass_addr)[:,1:-1]\n",
    "fitness,bestI,bestJ = two_point_bruteforce(np.array(minmax(pd.DataFrame(glass_dataset))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_dataset = read_df(glass_addr)[:,1:]\n",
    "fitness,bestI,bestJ = two_point_bruteforce(np.array(minmax(pd.DataFrame(glass_dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrence\n",
    "https://www.sciencedirect.com/science/article/pii/S095741740901063X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
